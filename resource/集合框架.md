# 集合框架

## Collection

### 1.List

#### 1.ArrayList

**1.线程不安全、底层是数组，因为他增删要移动元素、但是查询的时候可以通过索引值，所以他增删慢、查询快。**

**2.扩容机制：**

元素：elementData、size





初始化：this.elementData = new Object[0];

**add**    ->   ensureCapacityInternal(size+1)(**校验容量是否需要扩容**)  -> calculateCapacity (初始化赋值：**ele==null?Math.max(10, var1)**) -> ensureExplicitCapacity  (**if(size+1) > ele.length**) ->grow ( **ele.length+ (ele.length>> 1) 既1.5倍**)->

Arrays.copyOf（ele,newCap）(**此方法保留原来元素的结构的同时扩容指定长度**)

```java
public boolean add(E var1) {
    this.ensureCapacityInternal(this.size + 1);
    this.elementData[this.size++] = var1;
    return true;
}
```

remove : 主要：System.arraycopy();

**扩容流程：ArrayList的底层是一个数组，在使用无参构造器初始化的时候，它的底层数组是一个空数组。然后调用add方法，首先会进入一个ensurecapacityinternal,传入size+1这个值给mincapacity参数。然后他会进行比较，首先比较底层数组是否是空数组，若底层数组是空数组，则赋值mincapacity这个参数为10。若底层数组不为10，这个mincapacity就是size+1.这时候会使用mincapacity和底层的length进行比较，如果mincapacity参数值大于数组的长度时，就说明当前数组的长度已经不满足了新增操作的需求了，需要进行扩容，grow方法，第一次扩容的话是10，后面的每次扩容都是数组的长度的1.5倍。**



#### 2.Vector

**1.线程安全的、底层是数组，效率较低**

**2.扩容机制**

```java
//初始化
public Vector(){
	this(10);//赋值10个长度
}

public synchronized boolean add(E e) {
    modCount++;
    ensureCapacityHelper(elementCount + 1);
    elementData[elementCount++] = e;
    return true;
}
```

第一次赋10，第二次*2 。

算法是：**int newCapa = oldCap + ((capacityIncrement > 0) ? capacityIncrement : oldCapa);**
注：capacityIncrement 默认是0。



#### 3.LinkedList

**1.底层是双向链表、增删快、没有索引所以通过二分查找查询慢比ArrayList慢。**

**元素:**

```java
transient int size;
transient LinkedList.Node<E> first;
transient LinkedList.Node<E> last;
Node{
    E item;
    LinkedList.Node<E> next;
    LinkedList.Node<E> prev;
}
```

**2.add**

思路：新建新的节点->再赋值给旧last.next；

```java
void linkLast(E var1) {
    LinkedList.Node var2 = this.last;
    LinkedList.Node var3 = new LinkedList.Node(var2, var1, (LinkedList.Node)null);
    this.last = var3;
    if (var2 == null) {
        this.first = var3;
    } else {
        var2.next = var3;
    }

    ++this.size;
    ++this.modCount;
}
```

**3.remove**

**思路:  去除旧节点（help gc） -> 赋值first -> 赋值pre**

```java
 private E unlinkFirst(Node<E> f) {
     // assert f == first && f != null;
     final E element = f.item;
     final Node<E> next = f.next;
     f.item = null;
     f.next = null; // help GC
     first = next;
     if (next == null)
     last = null;
     else
     next.prev = null;
     size--;
     modCount++;
     return element;
 }
```

**4.get**

思路：二分查找

```java
LinkedList.Node<E> node(int var1) {
    LinkedList.Node var2;
    int var3;
    if (var1 < this.size >> 1) {
        var2 = this.first;
        for(var3 = 0; var3 < var1; ++var3) {
            var2 = var2.next;
        }
        return var2;
    } else {
        var2 = this.last;
        for(var3 = this.size - 1; var3 > var1; --var3) {
            var2 = var2.prev;
        }
        return var2;
    }
}
```



### 2.Set

#### 1.HashSet

**底层：hashmap(使用链表法)，插入无序，不可重复,不支持随机访问**** ****

**元素：** **PRESENT** 占位符  取值就是NULL ，占位底层map的value值

**loadFactor** 负载因子：在Map初始化时赋值，默认0.75。

默认长度：16，每次扩容<<1（2倍）即2的次幂

**数据结构：哈希表（数组+单链+红黑树）**

**避免碰撞：1.数组的长度始终保持为2的n次幂**

**2.让hash值的高位参与运算**

**3.通过位与来等价取模的操作**

**4.设置负载因子0.75**



**1.add**

**思路：其实就是调用hashmap的put方法，put（var1，present）**

**步骤：底层先调用map.put（key，PRESENT）；然后就是putVal（hash<key>,key,value,~,~）,然后判断底层table是否空，若空则扩容。无论是否扩容，下一步就是根据hash值算出索引值。根据索引值判断table中对应位置是否为空，若为空则添加，若不为空，则开始进入else里面，第一个判断第一个头结点是否相等，若不等则进行下一个节点的循环判断，想判空再判相等，如此反复，为空插入，重复break并返回oldvalue（重复的值）。在长度等于9的时候，数组长度大于等于64的时候就行树化。阈值是8.**

**hash值：hashcode值   ^（按位异或）hashcode>>>16，得出hash值。**

**索引值：hash值 &（与运算）（n-1）。n是底层数组长度。此方法保证了索引值在数组长度大小内**

**剪枝：size<6的时候红黑树转换成链表。**

**EntrySet、KeySet、Values保存着的是引用，并不保存数据。作用是为了Collection的遍历方法。**

**判重语句：既先判断hash，再比较(是否同一对象或者equals是否相等)。**

```
if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
```

1.执行 ***put()*** , 该方法会执行 hash(key) 得到key对应的hash值 算法**（h = key.hashCode()） ^ (h >>> 16)**

-->        ***putVal(hash(key), key, value, false, true);***    value就是present =  null

```java
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent, //onlyIfabsent 联系到重复key的代码，false时候新的值取代旧的值；
                   boolean evict) {                                //evict：false表示创建时调用，反之则创建后调用。
        Node<K, V>[] tab;
        Node<K, V> p;
        int n, i; //定义了辅助变量
        //table 就是 HashMap 的一个数组，类型是 Node[]
        //if 语句表示如果当前table 是null, 或者 大小=0
        //就是第一次扩容，到16个空间（默认长度）.临界区是16*0.75
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        //(1)根据key，得到hash 去计算该key应该存放到table表的哪个索引位置(i)
        //并把这个位置的对象，赋给 p
        //(2)判断p 是否为null
        //(2.1) 如果p 为null, 表示还没有存放元素, 就创建一个Node (key="java",value=PRESENT)
        //(2.2) 就放在该位置 tab[i] = newNode(hash, key, value, null)

        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            //一个开发技巧提示： 在需要局部变量(辅助变量)时候，在创建
            Node<K, V> e;
            K k; //
            //如果当前索引位置对应的链表的第一个元素和准备添加的key的hash值一样
            //并且满足 下面两个条件之一:
            //(1) 准备加入的key 和 p 指向的Node 结点的 key 是同一个对象
            //(2)  p 指向的Node 结点的 key 的equals() 和准备加入的key比较后相同
            //就不能加入
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
                //再判断 p 是不是一颗红黑树,
                //如果是一颗红黑树，就调用 putTreeVal , 来进行添加
            else if (p instanceof TreeNode)
                e = ((TreeNode<K, V>) p).putTreeVal(this, tab, hash, key, value);
            else {//如果table对应索引位置，已经是一个链表, 就使用for循环比较
                //(1) 依次和该链表的每一个元素比较后，都不相同, 则加入到该链表的最后
                //    注意在把元素添加到链表后，立即判断 该链表是否已经达到8个结点
                //    , 就调用 treeifyBin() 对当前这个链表进行树化(转成红黑树)
                //    注意，在转成红黑树时，要进行判断, 判断条件
                //    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY(64))
                //            resize();
                //    如果上面条件成立，先table扩容.
                //    只有上面条件不成立时，才进行转成红黑树
                //(2) 依次和该链表的每一个元素比较过程中，如果有相同情况,就直接break
-------------------------------- 尾随法
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD(8) - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
--------------------------------
            }
            if (e != null) { // 如果有重复的，e就不会空
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        //size 就是我们每加入一个结点Node(k,v,h,next), size++
        if (++size > threshold)
            resize();//扩容
        afterNodeInsertion(evict);
        return null;
    }
```



#### 2.LinkedHashSet

结构LinkedHashSet&Entry<K,V>   继承了HashMap&Node。

其实就是增加了head、tail。Node增加了before和after。

#### 3.TreeSet（TreeMap）

有序的hashmap。默认的时候是正序排序，创建时可以指定比较器。无参构造方法会调用默认的比较器，所以key必须实现一个比较器。

**核心代码：**

```java
   1. 构造器把传入的比较器对象，赋给了 TreeSet的底层的 TreeMap的属性this.comparator
    public TreeMap(Comparator<? super K> comparator) {
            this.comparator = comparator;
        }
     2. 在 调用 treeSet.add("tom"), 在底层会执行到

         if (cpr != null) {//cpr 就是我们的匿名内部类(对象)
            do {
                parent = t;
                //动态绑定到我们的匿名内部类(对象)compare
                cmp = cpr.compare(key, t.key);
                if (cmp < 0)
                    t = t.left;
                else if (cmp > 0)
                    t = t.right;
                else //如果相等，即返回0,这个Key就没有加入
                    return t.setValue(value);
            } while (t != null);
        }
     */
```




## Map

### 1.ConcurrentHashMap

内部结构：

```java
concurrentHashMap：
    //盛装Node元素的数组 它的大小是2的整数次幂
    transient volatile Node<K,V>[] table;
     /*hash表初始化或扩容时的一个控制位标识量。
     负数代表正在进行初始化或扩容操作
     -1代表正在初始化
     -N 表示有N-1个线程正在进行扩容操作
     正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小
     */
    private transient volatile int sizeCtl; 
    // 以下两个是用来控制扩容的时候 单线程进入的变量
    private static int RESIZE_STAMP_BITS = 16;
    private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;
    static final int MOVED     = -1; // hash值是-1，表示这是一个forwardNode节点
    static final int TREEBIN   = -2; // hash值是-2  表示这时一个TreeBin节点

Segment：
static final int MAX SCAN RETRIES =Runtime.getRuntime( ).availableProcessors() >1 ?64 : 1; 重试次数
transient volatile HashEntry<K,V>[ ] table;
transient int count;
transient int modCount;
transient int threshold;
final float loadFactor;


```



### 2.Hashmap

**put实现：看HashSet**

### 3.Hashtable

**1.线程安全的.**

**2.k-V 都不能为空，否则会抛出NullPointerException异常。**

**3.扩容机制  是初始11，负载因子0.75 。扩容算法(11<<1) * 0.75**

### 4.properties

**1.properties主要用作配置文件。具体用法请参考io。**



## 常用API

**ArrayList：**都是方法

1) add:添加单个元素
2) remove:删除指定元素
3) contains:查找元素是否存在
4) size:获取元素个数
5) isEmpty:判断是否为空
6) clear:清空
7) addAll:添加多个元素
8) containsAll:查找多个元素是否都存在
9) removeAll:删除多个元素



## 问题

#### 1.List去重

 **1.set.addAll(list);**

**2.List<String> listNew = new ArrayList<String>(new TreeSet<String>(list));**

```java
方案一:借助Set的特性进行去重
 	/**
     * 去除重复数据
     * 由于Set的无序性，不会保持原来顺序
     * @param list
     */
    public static List<String> list distinct(List<String> list) {
        final boolean sta = null != list && list.size() > 0;
        List doubleList= new ArrayList();
        if (sta) {
            Set set = new HashSet();
            set.addAll(list);
            doubleList.addAll(set);
        }
        return doubleList;
    }

方案二 : 利用set集合特性保持顺序一致去重
// Set去重并保持原先顺序的两种方法
   public static void delRepeat(List<String> list) {
   	   //方法一
       List<String> listNew = new ArrayList<String>(new TreeSet<String>(list));
       //方法二
       List<String> listNew2 = new ArrayList<String>(new LinkedHashSet<String>(list));
   }

```

#### 2. 为什么模总是2的n次幂

**第一，关于扩容的操作只需左移即可，这个up主有讲。**
**第二，是为了hash均匀分布的问题，假设没有减一，大小直接是2次幂，比如100000这样的数，直接做&运算的结果可想而之，无论你的hash算法多么精妙绝伦，这个导致的碰撞几率会相当高，而减1变成类似于1111这样的二进制分布，&运算会保持hash本身的分布，不会损坏hash计算的结果，而这一点在hash时左移16位异或相呼应，高位与低位充分混合，减少碰撞概率。另外，hashmap也把大小限定在2次幂上，无论你自定义什么大小，始终会转换成大于这个数的最近2次幂。**



#### 3.关于
